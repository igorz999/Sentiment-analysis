{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c568d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset #ease batching/shuffleing of data, \n",
    "    # and for TensorDataset easy to use with Dataloader bc of easy pairing of input features with labels\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#izvlacimo preko regexa sve komentar klase na nekom sajtu(scraping)\n",
    "reviews = []\n",
    "\n",
    "#ovo vadi samo sa glavne strane reviewove zato ih umesto po 88 da ima npr na sajtu kafica ima u vrh glave 10ak\n",
    "urls = [\n",
    "    'https://www.yelp.com/biz/pronto-pizza-san-francisco?hrid=MqOAQdGM98FDpHqArFRZFg',\n",
    "    'https://www.yelp.com/biz/mejico-sydney-2',\n",
    "    'https://www.yelp.com/biz/vans-daly-city',\n",
    "    'https://www.yelp.com/biz/dhoom-indian-fashion-clothing-and-bridal-fremont-3',\n",
    "    'https://www.yelp.com/biz/san-francisco-centre-san-francisco?osq=Shopping',\n",
    "    'https://www.yelp.com/biz/sanraku-san-francisco-2'\n",
    "]\n",
    "\n",
    "#implement error handling!\n",
    "def fetch_reviews(urls):\n",
    "    for url in urls:\n",
    "        r = requests.get(url) #dohvatamo sve sa tog sajta, r.text je citav tekst\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        regex = re.compile('.*comment.*') #trazimo klase \"comment\" jer se tu zapravo nalaze review-ovi\n",
    "        results = soup.find_all('p', {'class':regex}) # p znaci paragrafe trazimo, zatim trazimo sve sto je klase comment\n",
    "        reviews.extend([result.text for result in results]) #izvlacimo samo text iz html dela\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e930ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = fetch_reviews(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a407603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(reviews) #mali je broj instanci za kvalitetan model? (za sad 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sad cemo ubaciti review-ove u dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.array(reviews), columns=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df729def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good neighborhood pizza joint.  Not gourmet--n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All I can say is Wow .... Go Pronto!From the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recently placed an order from Pronto Pizzeria ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pizza is great but don't skip on this sandwich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't be fooled by its location. As nasty as i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Hi Katherine, thank you very much for your rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Not  great. Undon was a little bland and chick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Hi Nikki, thank you very much for your honest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Three months ago I was in The Bay area and wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Hi Ashley, thank you very much for your great ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review\n",
       "0   Good neighborhood pizza joint.  Not gourmet--n...\n",
       "1   All I can say is Wow .... Go Pronto!From the m...\n",
       "2   Recently placed an order from Pronto Pizzeria ...\n",
       "3   Pizza is great but don't skip on this sandwich...\n",
       "4   Don't be fooled by its location. As nasty as i...\n",
       "..                                                ...\n",
       "66  Hi Katherine, thank you very much for your rev...\n",
       "67  Not  great. Undon was a little bland and chick...\n",
       "68  Hi Nikki, thank you very much for your honest ...\n",
       "69  Three months ago I was in The Bay area and wen...\n",
       "70  Hi Ashley, thank you very much for your great ...\n",
       "\n",
       "[71 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fa962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dfde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(review):\n",
    "    tokens = tokenizer.encode(review, return_tensors='pt', truncation=True, max_length=512)\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d501269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['review'].apply(lambda x: sentiment_score(x)) #nlp pipeline je limitirana sa koliko mozes tokena da posaljes(max je 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6efc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882dc231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Hi Katherine, thank you very much for your rev...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Not  great. Undon was a little bland and chick...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Hi Nikki, thank you very much for your honest ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Three months ago I was in The Bay area and wen...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Hi Ashley, thank you very much for your great ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  sentiment\n",
       "66  Hi Katherine, thank you very much for your rev...          4\n",
       "67  Not  great. Undon was a little bland and chick...          2\n",
       "68  Hi Nikki, thank you very much for your honest ...          4\n",
       "69  Three months ago I was in The Bay area and wen...          4\n",
       "70  Hi Ashley, thank you very much for your great ...          4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857adb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(\n",
    "        texts.tolist(), max_length=max_length, truncation=True, padding=True, return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00cc807",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = encode_data(X_train, tokenizer)\n",
    "test_encodings = encode_data(X_test, tokenizer)\n",
    "#input_ids: the numerical representations of the tokens in the text.\n",
    "#attention_mask: This indicates which tokens should be attended to and which should be ignored (padding tokens).\n",
    "#Tokenization converts text into a format suitable for the model, and these encodings are used as input to the BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec38659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(y_train.values, dtype=torch.long)\n",
    "test_labels = torch.tensor(y_test.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac38609",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87543e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=3e-5, no_deprecation_warning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471aae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.3819330632686615\n",
      "epoch: 1, loss: 0.7227057218551636\n",
      "epoch: 1, loss: 0.264137864112854\n",
      "epoch: 1, loss: 0.3776280879974365\n",
      "epoch: 2, loss: 0.15438351035118103\n",
      "epoch: 2, loss: 0.17540502548217773\n",
      "epoch: 2, loss: 0.33494317531585693\n",
      "epoch: 2, loss: 0.11054343730211258\n",
      "epoch: 3, loss: 0.06401576846837997\n",
      "epoch: 3, loss: 0.16015514731407166\n",
      "epoch: 3, loss: 0.08508225530385971\n",
      "epoch: 3, loss: 0.07548914849758148\n"
     ]
    }
   ],
   "source": [
    "#train loop\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad() #clearing the gradients from the previous step\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch] #unpacking the batch of data\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels = labels) #forward pass(computing the model outputs)\n",
    "        loss = outputs.loss #getting the loss from the outputs\n",
    "        loss.backward() #compute the gradients of the loss\n",
    "        optimizer.step() #update the model parameters using optimizer\n",
    "        print(f\"epoch: {epoch + 1}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d880c562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.22240297496318817\n",
      "Test Accuracy: 93.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       1.00      0.50      0.67         2\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.92      0.88      0.87        15\n",
      "weighted avg       0.96      0.93      0.93        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "correct_pred = 0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        correct_pred += (predictions == labels).sum().item()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "avg_loss = total_loss / len(test_loader)\n",
    "accuracy = correct_pred / len(test_dataset)\n",
    "print(f\"Test Loss: {avg_loss}\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aba11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer1\\\\tokenizer_config.json',\n",
       " 'tokenizer1\\\\special_tokens_map.json',\n",
       " 'tokenizer1\\\\vocab.txt',\n",
       " 'tokenizer1\\\\added_tokens.json',\n",
       " 'tokenizer1\\\\tokenizer.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#saving the model for future use\n",
    "model.save_pretrained('model1')\n",
    "tokenizer.save_pretrained('tokenizer1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75941fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3739c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
